{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b005e1",
   "metadata": {},
   "source": [
    "# Notebook Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae995ec",
   "metadata": {},
   "source": [
    "In this notebook, we perform an Exploratory Data Analysis on a dataset and train a machine learningng model that classifies patients in the ICU that will develop Sepsis and those that will not develop Sepsis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8493f21c",
   "metadata": {},
   "source": [
    "# Set Up\n",
    "\n",
    "\n",
    "\n",
    "**Installation**\n",
    "\n",
    "Here is the section where we installed all the packages/libraries that will be needed to tackle the challlenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94ac78a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3424016597.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [1], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install scikit-learn==1.0.2\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Installatin of packages\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install patool\n",
    "#!pip install forex_python\n",
    "#!pip install pandas_profiling\n",
    "#! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip \n",
    "#!pip install -U imbalanced-learn\n",
    "pip install scikit-learn==1.0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3fc09",
   "metadata": {},
   "source": [
    "# Importation\n",
    "Here is the section to import all the packages/libraries that will be used through this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from forex_python.converter import CurrencyRates\n",
    "from babel.numbers import format_currency\n",
    "import datetime as dt\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, trim_mean, mstats, mode\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "# Vizualisation (Matplotlib, Plotly, Seaborn, etc. )\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "\n",
    "# balance data\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Machine learning libraries and metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Feature Processing (Scikit-learn processing, etc. )\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, LabelEncoder, Binarizer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score,roc_curve, auc,roc_auc_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import joblib\n",
    "# Other packages\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import patoolib\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013fad7",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Here is the section to load the datasets (train, eval, test) and the additional files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604bde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testurl=\"https://raw.githubusercontent.com/Gilbert-B/Machine-Learning-API-using-FastAPI/main/assets/datasets/Paitients_Files_Test.csv\"\n",
    "trainurl=\"https://raw.githubusercontent.com/Gilbert-B/Machine-Learning-API-using-FastAPI/main/assets/datasets/Paitients_Files_Train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c283e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(testurl,error_bad_lines=False)\n",
    "train_df= pd.read_csv(trainurl,error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19df1a8",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: EDA\n",
    "Here is the section to **inspect** the datasets in depth, **present** it, make **hypotheses** and **think** the *cleaning, processing and features creation*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5be18",
   "metadata": {},
   "source": [
    "## Dataset overview\n",
    "\n",
    "Have a look at the loaded datsets using the following methods: `.head(), .info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d45196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick look at the shape of our dataset\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the head of our dataset\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a look at the tail\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c73528",
   "metadata": {},
   "source": [
    "##### Description of Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9ebf3",
   "metadata": {},
   "source": [
    "ID\t-\tUnique number to represent patient ID\n",
    "\n",
    "PRG - \tPlasma glucose\n",
    "\n",
    "PL\t-\tBlood Work Result-1 (mu U/ml)\n",
    "\n",
    "PR\t-\tBlood Pressure (mm Hg) \n",
    "\n",
    "SK\t-\tBlood Work Result-2 (mm)\n",
    "\n",
    "TS\t-   Blood Work Result-3 (mu U/ml)\n",
    "\n",
    "M11\t-\tBody mass index (weight in kg/(height in m)^2\n",
    "\n",
    "BD2\t-\tBlood Work Result-4 (mu U/ml)\n",
    "\n",
    "Age\t-\tpatients age (years)\n",
    "\n",
    "Insurance\t- If a patient holds a valid insurance card\n",
    "\n",
    "Sepssis\tTarget\tPositive: if a patient in ICU will develop a sepsis , and Negative: otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39254798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Look at the columns in the dataset and their data types\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Look at the columns in the dataset and their data types\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb4495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get more details about the features of our data\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "train_df.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for outliers\n",
    "train_df.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b554c42",
   "metadata": {},
   "source": [
    "## Issues With the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b6fe9",
   "metadata": {},
   "source": [
    "\n",
    "Too many zeros in each column\n",
    "\n",
    "The column names are not very descriptive.\n",
    "\n",
    "The target variable 'Sepssis' may have imbalanced classes.\n",
    "\n",
    "There are many outliers in some of the numerical columns.\n",
    "\n",
    "There could be correlations between some of the predictor variables, leading to multicollinearity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38e7f0",
   "metadata": {},
   "source": [
    "## How I Intend to Solve Them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13472da9",
   "metadata": {},
   "source": [
    "Replace zeros in each column with the median value\n",
    "\n",
    "Rename the column names to be more descriptive and easier to understand.\n",
    "\n",
    "Handle the imbalanced classes in the target variable using techniques such as undersampling or oversampling.\n",
    "\n",
    "Use visualization techniques such as box plots and scatter plots to identify and handle any outliers.\n",
    "\n",
    "Use correlation analysis to identify highly correlated variables and consider dropping or transforming them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6db03",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d6624",
   "metadata": {},
   "source": [
    "***Null Hypothesis:*** Age does not determine whether a patient will develop Sepssis\n",
    "\n",
    "***Alternate Hypothesis:*** Age determines whether a pateint will develop Sepssis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c11a7e",
   "metadata": {},
   "source": [
    "##  Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa52b8da",
   "metadata": {},
   "source": [
    "1. Is the train dataset complete?\n",
    "2. What are the ages of the youngest and oldest patients?\n",
    "3. What are the youngest and oldest patients with Sepssis?\n",
    "4. What is the average age ?\n",
    "5. What is the ratio of patients who are positive for sepssis to the negative patients ?\n",
    "6. What is the highest and lowest BMI?\n",
    "7. What is the average BMI ?\n",
    "8. Is there a corelation between the Sepssis status and the other attributes? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb60d8",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Rename the columns\n",
    "train_df = train_df.rename(columns={\n",
    "    \"PRG\": \"Plasma_glucose\",\n",
    "    \"PL\": \"Blood_Work_R1\",\n",
    "    \"PR\": \"Blood_Pressure\",\n",
    "    \"SK\": \"Blood_Work_R2\",\n",
    "    \"TS\": \"Blood_Work_R3\",\n",
    "    \"M11\": \"BMI\",\n",
    "    \"BD2\": \"Blood_Work_R4\",\n",
    "    \"Age\": \"Patient_age\",\n",
    "    \"Sepssis\": \"Target\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaee2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['Plasma_glucose', 'Blood_Work_R1', 'Blood_Pressure', 'Blood_Work_R2', 'Blood_Work_R3', 'BMI', 'Blood_Work_R4', 'Patient_age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f085d",
   "metadata": {},
   "source": [
    "##### Removing the rows where BMI is 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets inspect our dataset again\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d63752",
   "metadata": {},
   "source": [
    "A glance at our dataset shows the value 0 in some of the columns. This can not be possible and indicates the presence of wrong vaules in our dataset. Lets first remove 0 BMIs and replace the other 0 values in the columns with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18981dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting rows with 0 BMI\n",
    "zero_bmi = train_df[train_df['BMI']==0.0]\n",
    "zero_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows with 0 BMI\n",
    "train_df.drop(train_df[train_df['BMI'] == 0.0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming that all 0 BMIs have been removed from our dataset\n",
    "zero_bmi2 = train_df[train_df['BMI']==0.0]\n",
    "zero_bmi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549d8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15fa417f",
   "metadata": {},
   "source": [
    "##### Replace zeros in other  columns  with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another look at our dataset shows that most of our columns have 0 for values.\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_too_many_zeros = ['Plasma_glucose', 'Blood_Work_R2', 'Blood_Work_R3']\n",
    "for col in columns_with_too_many_zeros:\n",
    "    train_df[col].replace(to_replace=0, value=train_df[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606855b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d1fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a153870c",
   "metadata": {},
   "source": [
    "#### Checking for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be6d6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the boxplot\n",
    "train_df.boxplot()\n",
    "\n",
    "# Rotate x-axis labels by 45 degrees\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628451e",
   "metadata": {},
   "source": [
    "The box plots of the various columns as visualized above, shows the presence of outliers in our data.\n",
    "Outliers can skew the results of machine learning models and make them less accurate and reliable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2af42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = train_df.quantile(0.25)\n",
    "Q3 = train_df.quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "IQR\n",
    "((train_df< (Q1-1.5 * IQR)) | (train_df > (Q3 + 1.5 * IQR))).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff49e4",
   "metadata": {},
   "source": [
    "All the columns except ID, Insurance and the Target Column have outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b208da57",
   "metadata": {},
   "source": [
    "#### Calculating the Interquartile range, setting the outlier boundary and removing the outliers from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ec563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns of interest\n",
    "columns_of_interest =  ['BMI', 'Blood_Pressure', 'Blood_Work_R1','Blood_Work_R2','Blood_Work_R3','Blood_Work_R4','Patient_age','Plasma_glucose']\n",
    "\n",
    "# Check if outliers still exist in the columns\n",
    "outliers_exist = False\n",
    "\n",
    "for column in columns_of_interest:\n",
    "    # Calculate the first and third quartiles (Q1 and Q3)\n",
    "    Q1 = train_df[column].quantile(0.25)\n",
    "    Q3 = train_df[column].quantile(0.75)\n",
    "\n",
    "    # Calculate the interquartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Modify the values in the column to be within the range\n",
    "    train_df[column] = train_df[column].clip(lower_bound, upper_bound)\n",
    "\n",
    "    # Check if outliers exist in the column\n",
    "    if (train_df[column] < lower_bound).any() or (train_df[column] > upper_bound).any():\n",
    "        outliers_exist = True\n",
    "        print(f\"Outliers still exist in '{column}'.\")\n",
    "\n",
    "if not outliers_exist:\n",
    "    print(\"No outliers exist in the specified columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca141ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the boxplot\n",
    "train_df.boxplot()\n",
    "\n",
    "# Rotate x-axis labels by 45 degrees\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b6a73",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309dcc0a",
   "metadata": {},
   "source": [
    "#### Positive Sepssis Cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571eccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "positive_cases = train_df[train_df['Target'] == 'Positive']\n",
    "positive_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56b17c8",
   "metadata": {},
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feacd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_age_stats = positive_cases['Patient_age'].describe()\n",
    "positive_age_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a847ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_positives= positive_age_stats['count']\n",
    "print(f'The no of patients diagnosed with Sepssis is {no_positives}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_mean_age = positive_age_stats['mean']\n",
    "print(f'The mean age of patients with Sepssis is: {positive_mean_age:.2f} years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d68088",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_positive_age = positive_age_stats['max']\n",
    "print(f'The oldest patient with Sepssis is {highest_positive_age} years old')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_positive_age = positive_age_stats['min']\n",
    "print(f'The youngest patient with Sepssis is {lowest_positive_age} years old')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'age' column from the DataFrame\n",
    "ages = positive_cases['Patient_age']\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(ages, bins=20, edgecolor='black')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Ages of Patients with Sepssis')\n",
    "plt.show()\n",
    "\n",
    "# Create a kernel density plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sn.kdeplot(ages, shade=True, color='blue', linewidth=2)\n",
    "plt.axvline(positive_mean_age, color='red', linestyle='--', label='Mean Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Ages of Patients with Sepssis (Kernel Density Plot)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bffa58",
   "metadata": {},
   "source": [
    "BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10595bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bmi_stats = positive_cases['BMI'].describe()\n",
    "positive_bmi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4990974",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_mean_bmi = positive_bmi_stats['mean']\n",
    "print(f'The average BMI for patients with Sepssis is {positive_mean_bmi:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fedd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_bmi = positive_bmi_stats['max']\n",
    "print(f'The highest BMI for a patient with Sepssis is {highest_bmi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_positive_bmi = positive_bmi_stats['min']\n",
    "print(f'The lowest BMI for a patient with Sepssis is {lowest_positive_bmi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the BMI 'M11' column from the DataFrame\n",
    "BMI = positive_cases['BMI']\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(ages, bins=20, edgecolor='black')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of BMI of Patients with Sepssis')\n",
    "plt.show()\n",
    "\n",
    "# Create a kernel density plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sn.kdeplot(BMI, shade=True, color='blue', linewidth=2)\n",
    "plt.axvline(positive_mean_age, color='red', linestyle='--', label='Mean BMI')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of BMI of Patients With Sepssis (Kernel Density Plot)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df44c0cb",
   "metadata": {},
   "source": [
    "#### Negative Sepssis Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224fd0b",
   "metadata": {},
   "source": [
    "AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9baf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cases = train_df[train_df['Target'] == 'Negative']\n",
    "negative_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b1fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_age_stats = negative_cases['Patient_age'].describe()\n",
    "negative_age_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb325f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Negative = negative_age_stats['count']\n",
    "print (f'No of patients without Sepssis is {No_Negative}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = negative_age_stats['mean']\n",
    "print(f'The mean age for patients without Sepssis is: {mean_age:.2f} years')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_negative_age = negative_age_stats['max']\n",
    "print(f'The oldest patient without Sepssis is {highest_negative_age} years old')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_negative_age = negative_age_stats['min']\n",
    "print(f'The youngest patient withot Sepssis is {lowest_negative_age} years old')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363136ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'age' column from the DataFrame\n",
    "ages = negative_cases['Patient_age']\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(ages, bins=20, edgecolor='black')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Ages of Patients without Sepssis')\n",
    "plt.show()\n",
    "\n",
    "# Create a kernel density plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sn.kdeplot(ages, shade=True, color='blue', linewidth=2)\n",
    "plt.axvline(positive_mean_age, color='red', linestyle='--', label='Mean Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Ages of Patients without Sepssis (Kernel Density Plot)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3318e41",
   "metadata": {},
   "source": [
    "BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08560c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_bmi_stats = negative_cases['BMI'].describe()\n",
    "negative_bmi_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78609989",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mean_bmi = negative_bmi_stats['mean']\n",
    "print(f'The mean BMI for patients without Sepssis is: {negative_mean_bmi:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_negative_bmi = negative_bmi_stats['max']\n",
    "print(f'The highest BMI for a  patient without Sepssis is {highest_negative_bmi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_negative_bmi = negative_bmi_stats['min']\n",
    "print(f'The lowest BMI for a patient withot Sepssis is {lowest_negative_bmi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the BMI 'M11' column from the DataFrame\n",
    "BMI = negative_cases['BMI']\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(ages, bins=20, edgecolor='black')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of BMI of Patients Without Sepssis')\n",
    "plt.show()\n",
    "\n",
    "# Create a kernel density plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sn.kdeplot(BMI, shade=True, color='blue', linewidth=2)\n",
    "plt.axvline(negative_mean_bmi, color='red', linestyle='--', label='Mean BMI')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of BMI of Patients Without Sepssis (Kernel Density Plot)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182aba7",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50867eb2",
   "metadata": {},
   "source": [
    "#### Graphically Displaying all other numerical columns using Histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca87df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for the plot\n",
    "sn.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# Create a grid of 3 by 3 subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "# Flatten the axes array\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot histograms for each numerical column\n",
    "for i, col in enumerate(numerical_features):\n",
    "    sn.histplot(data=train_df, x=col, kde=True, bins=10, ax=axes[i])\n",
    "    axes[i].set_title(f'Histogram of {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613779b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Distribution of the target variable (Sepssis)\n",
    "sn.countplot(x='Target', data=train_df)\n",
    "plt.title('Distribution of Sepssis')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot to visualize relationships between variables\n",
    "sn.pairplot(train_df, hue='Target', diag_kind='kde')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sn.heatmap(train_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a5869",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Boxplots of numerical variables grouped by Sepssis Target\n",
    "numeric_columns = ['Plasma_glucose', 'Blood_Work_R1', 'Blood_Pressure', 'Blood_Work_R2', 'Blood_Work_R3', 'BMI', 'Blood_Work_R4', 'Patient_age']\n",
    "for column in numeric_columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sn.boxplot(x='Target', y=column, data=train_df)\n",
    "    plt.title('Boxplot of ' + column + ' grouped by Sepssis Status')\n",
    "    plt.show()\n",
    "\n",
    "# Histograms of numerical variables grouped by Sepssis Target\n",
    "for column in numeric_columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sn.histplot(data=train_df, x=column, hue='Target', kde=True)\n",
    "    plt.title('Histogram of ' + column + ' grouped by Sepssis  Status')\n",
    "    plt.show()\n",
    "\n",
    "# Bar plots of categorical variable (Insurance) grouped by Sepssis Target\n",
    "plt.figure(figsize=(8, 6))\n",
    "sn.countplot(x='Insurance', hue='Target', data=train_df)\n",
    "plt.title('Count of Insurance grouped by Sepssis Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d98ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sn.histplot(data=train_df, x='Patient_age', hue='Target', alpha=0.5, kde=True)\n",
    "plt.title(f'Histogram of Patient_age')\n",
    "plt.xlabel('Patient_age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252aab1b",
   "metadata": {},
   "source": [
    "## Hypothesis Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521176bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into two groups based on the Sepssis variable\n",
    "target_positive = train_df[train_df['Target'] == 'Positive']\n",
    "target_negative= train_df[train_df['Target'] == 'Negative']\n",
    "\n",
    "# Extract the Age(Patient_age) values for each group\n",
    "age_target_positive = target_positive['Patient_age']\n",
    "age_target_negative = target_negative['Patient_age']\n",
    "\n",
    "# Perform independent samples t-test\n",
    "t_statistic, p_value = ttest_ind(age_target_positive, age_target_negative)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Based on the t-test results, the t-statistic value is {} and the p-value is {}.\".format(t_statistic, p_value))\n",
    "print(\"\\nInterpreting the results:\")\n",
    "print(\"T-Statistic: The t-statistic measures the difference between the means of the two groups (positive and negative Sepssis Target) relative to the variability within each group. In this case,the t-statistic value of {} indicates a substantial difference in the mean age between the two groups.\".format(t_statistic))\n",
    "print(\"P-Value: The p-value is a measure of the statistical significance of the t-test results.In this case,the p-value is very small, which is less than commonly used significance levels like 0.05 or 0.01.This indicates strong evidence against the null hypothesis.\")\n",
    "print(\"\\nInterpretation: With a t-statistic of {} and a very small p-value of {}, we can conclude that there is a significant difference in the mean age between patients with a positive Sepssis status and those with a negative Sepssis status. The results suggest that age may play a role in determining the likelihood of developing sepsis.\".format(t_statistic, p_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ddc3c1",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356cc5a3",
   "metadata": {},
   "source": [
    "#### 1. Is the train dataset complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a611e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2e0f9",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555f897",
   "metadata": {},
   "source": [
    "#### 2. What are the ages of the youngest and oldest patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_age = train_df['Patient_age'].max()\n",
    "youngest_age= train_df['Patient_age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99859d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The youngest and oldest patients are {youngest_age} and {oldest_age} years respectively')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f2303",
   "metadata": {},
   "source": [
    "#### 3. What are the youngest and oldest patients with Sepssis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d12c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_positive_age = positive_age_stats['max']\n",
    "lowest_positive_age = positive_age_stats['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b3a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The youngest and oldest patient with Sepssis is {lowest_positive_age} and {highest_positive_age} years respectively')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbd92f",
   "metadata": {},
   "source": [
    "#### 4. What is the average age ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35228d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_age = train_df['Patient_age'].mean()\n",
    "print(f'The Average age is {average_age:.2f} years old')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d24973",
   "metadata": {},
   "source": [
    "#### 5. What is the ratio of patients who are positive for sepssis to the negative patients ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count of positive and negative patients\n",
    "positive_count = train_df[train_df['Target'] == 'Positive'].shape[0]\n",
    "negative_count = train_df[train_df['Target'] == 'Negative'].shape[0]\n",
    "\n",
    "# Calculate the ratio\n",
    "ratio = positive_count / negative_count\n",
    "\n",
    "print(f'The ratio of patientrs positive for sepssis to negative patients is {ratio:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc9a02",
   "metadata": {},
   "source": [
    "#### 6.What is the highest and lowest BMI?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_bmi = train_df['BMI'].max()\n",
    "lowest_bmi= train_df['BMI'].min()\n",
    "\n",
    "print(f'The highest and lowest BMI is {highest_bmi:.2f} and {lowest_bmi:.2f} respectively')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4658f06",
   "metadata": {},
   "source": [
    "#### 7.What is the average BMI ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b99341",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_bmi = train_df['BMI'].mean()\n",
    "\n",
    "print(f'The average BMI is {average_bmi:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745855c0",
   "metadata": {},
   "source": [
    "#### 8.Is there a corelation between the Sepssis status and the other attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328bba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"Positive\" with 1 and \"Negative\" with 0\n",
    "train_df['Target'] = train_df['Target'].replace({'Positive': 1, 'Negative': 0})\n",
    "\n",
    "# Print the updated DataFrame\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5988ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = train_df.corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sn.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cccbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = train_df.corr()\n",
    "\n",
    "# Create a DataFrame from the correlation matrix\n",
    "correlation_table = pd.DataFrame(correlation_matrix)\n",
    "\n",
    "# Print the correlation table\n",
    "correlation_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d934d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set the threshold for high correlation\n",
    "threshold = 0.5\n",
    "\n",
    "# Find the highly correlated variables\n",
    "high_correlation = (correlation_matrix.abs() > threshold) & (correlation_matrix != 1)\n",
    "\n",
    "# Get the variable pairs with high correlation\n",
    "high_correlation_pairs = [(i, j) for i in high_correlation.columns for j in high_correlation.columns if high_correlation.loc[i, j]]\n",
    "\n",
    "# Print the highly correlated variables\n",
    "for pair in high_correlation_pairs:\n",
    "    var1, var2 = pair\n",
    "    correlation_value = correlation_matrix.loc[var1, var2]\n",
    "    print(f\"{var1} and {var2} are highly correlated (correlation value: {correlation_value})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377abec9",
   "metadata": {},
   "source": [
    "## Feature Processing and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592fdeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa44623",
   "metadata": {},
   "source": [
    "#### Check and Drop Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d160521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicate rows in data\n",
    "duplicate_rows = train_df.duplicated()\n",
    "print(\"Number of duplicate rows:\", duplicate_rows.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7072c",
   "metadata": {},
   "source": [
    "#### Impute Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83f5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = train_df.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d93a3d",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2897fb6",
   "metadata": {},
   "source": [
    "##### Removing Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Plasma_Glucose and Patient_age are highly correlated, we will remove Plasma_Glucose \n",
    "# We will remove Blood_work_R2 since it is also highly correlated to BMI\n",
    "# We will remove the ID column\n",
    "# we drop Insurance as well since it isnt a relevant field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_new = train_df.drop(['Blood_Work_R2', 'Plasma_glucose', 'ID', 'Insurance'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242aa0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc072220",
   "metadata": {},
   "source": [
    "## Data Spliting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf361152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split with a random_state, and add stratify for Classification\n",
    "# Split the  data into train and validation sets\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(train_df_new.iloc[:, :-1], train_df_new.iloc[:, -1:],\n",
    "                                                    test_size=0.2, random_state=42, stratify=train_df_new.iloc[:, -1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c23f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_eval.shape,y_train.shape,y_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca45b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5af438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27a417a",
   "metadata": {},
   "source": [
    "## Feature Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa88e7f",
   "metadata": {},
   "source": [
    "#### Checking to see if Our Data is Balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1d4da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the occurrences of each class label\n",
    "class_counts = train_df['Target'].value_counts()\n",
    "\n",
    "# Print the class counts\n",
    "print(class_counts)\n",
    "\n",
    "# Calculate the class frequencies\n",
    "class_frequencies = class_counts / len(train_df)\n",
    "\n",
    "# Print the class frequencies\n",
    "print(class_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset is imbalanced and we would have to Scale it \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns = ['Blood_Work_R1', 'Blood_Pressure', 'Blood_Work_R3', 'BMI', 'Blood_Work_R4', 'Patient_age'])\n",
    "\n",
    "X_eval_scaled = scaler.transform(X_eval)\n",
    "X_eval_df = pd.DataFrame(X_eval_scaled, columns = ['Blood_Work_R1', 'Blood_Pressure','Blood_Work_R3', 'BMI', 'Blood_Work_R4', 'Patient_age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ba14b",
   "metadata": {},
   "source": [
    "# Machine Learing Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1940513",
   "metadata": {},
   "source": [
    "#### Here is the section to build, train, evaluate and compare the models to each others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e530208",
   "metadata": {},
   "source": [
    "## Logistics Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the model\n",
    "\n",
    "lr = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training set\n",
    "\n",
    "lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d41124",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb353b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report for the model's performance on the eval set.\n",
    "LRM=(classification_report(y_eval, y_pred))\n",
    "\n",
    "\n",
    "print(LRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the classification report string\n",
    "def parse_classification_report(LRM):\n",
    "    lines = LRM.strip().split('\\n')\n",
    "    metrics = {}\n",
    "    for line in lines[2:4]:  # Only parse the lines for class 0 and class 1\n",
    "        label, precision, recall, f1_score, _ = line.split()\n",
    "        metrics[f'precision_{label}'] = float(precision)\n",
    "        metrics[f'recall_{label}'] = float(recall)\n",
    "        metrics[f'f1-score_{label}'] = float(f1_score)\n",
    "    return metrics\n",
    "\n",
    "# Call the function to parse the classification report string\n",
    "lr_metrics = parse_classification_report(LRM)\n",
    "\n",
    "print(lr_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0d64a",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.set_params(**{'n_estimators': 100, 'random_state': 42})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training set\n",
    "rfc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da368726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model on the Evaluation dataset \n",
    "y_pred = rfc.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908aa327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the valid metrics for the use case # Optional: show the classification report \n",
    "accuracy = accuracy_score(y_eval, y_pred)\n",
    "precision = precision_score(y_eval, y_pred)\n",
    "recall = recall_score(y_eval, y_pred)\n",
    "f1 = f1_score(y_eval, y_pred)\n",
    "\n",
    "\n",
    "#classification report for the model's performance on the eval set.\n",
    "RFCM=(classification_report(y_eval, y_pred))\n",
    "\n",
    "print(RFCM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0775c",
   "metadata": {},
   "source": [
    "For each model and class, we have the following metrics:\n",
    "\n",
    "Precision: It measures how many of the predicted positive instances are actually positive. A higher precision means fewer false positives.\n",
    "\n",
    "Recall: It measures how many of the actual positive instances are correctly identified. A higher recall means fewer false negatives.\n",
    "\n",
    "F1-score: It is a balanced measure that combines both precision and recall. It provides a single value that represents the model's overall performance for a specific class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the classification report string\n",
    "def parse_classification_report(RFCM):\n",
    "    lines = RFCM.strip().split('\\n')\n",
    "    metrics = {}\n",
    "    for line in lines[2:4]:  # Only parse the lines for class 0 and class 1\n",
    "        label, precision, recall, f1_score, _ = line.split()\n",
    "        metrics[f'precision_{label}'] = float(precision)\n",
    "        metrics[f'recall_{label}'] = float(recall)\n",
    "        metrics[f'f1-score_{label}'] = float(f1_score)\n",
    "    return metrics\n",
    "\n",
    "# Call the function to parse the classification report string\n",
    "rfc_metrics = parse_classification_report(RFCM)\n",
    "\n",
    "print(rfc_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c9dd3",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2594f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with default hyperparameters\n",
    "gbc = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1528c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "gbc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcaff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the evaluation set\n",
    "y_pred = gbc.predict(X_eval_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80576c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report for the model's performance on the evalset.\n",
    "GBCM= (classification_report(y_eval, y_pred))\n",
    "\n",
    "\n",
    "print(GBCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c68a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the classification report string\n",
    "def parse_classification_report(GBCM):\n",
    "    lines = GBCM.strip().split('\\n')\n",
    "    metrics = {}\n",
    "    for line in lines[2:4]:  # Only parse the lines for class 0 and class 1\n",
    "        label, precision, recall, f1_score, _ = line.split()\n",
    "        metrics[f'precision_{label}'] = float(precision)\n",
    "        metrics[f'recall_{label}'] = float(recall)\n",
    "        metrics[f'f1-score_{label}'] = float(f1_score)\n",
    "    return metrics\n",
    "\n",
    "# Call the function to parse the classification report string\n",
    "gbc_metrics = parse_classification_report(GBCM)\n",
    "\n",
    "print(gbc_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe28a4",
   "metadata": {},
   "source": [
    "# Models comparison\n",
    "\n",
    "Creating a pandas dataframe that will allow us to compare our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append('RFC')\n",
    "models.append('GBC')\n",
    "models.append('LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [rfc_metrics, gbc_metrics, lr_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics = []\n",
    "for i, m in enumerate(metrics_list):\n",
    "    m['model'] = models[i]\n",
    "    combined_metrics.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693425f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(combined_metrics)\n",
    "metrics_df.set_index('model', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8e89a",
   "metadata": {},
   "source": [
    "If we consider the F1-score as the evaluation criterion, we can compare the F1-scores for each model and class. Generally, a higher F1-score indicates better performance in terms of both precision and recall.\n",
    "\n",
    "Looking at the F1-scores in the table:\n",
    "\n",
    "For class 0, the GBC model has the highest F1-score of 0.84, followed by the RFC model with an F1-score of 0.84, and the LR model with an F1-score of 0.83.\n",
    "For class 1, the GBC model has the highest F1-score of 0.73, followed by the RFC model with an F1-score of 0.68, and the LR model with an F1-score of 0.63.\n",
    "Based on the F1-scores, we can conclude that the GBC model performed the best for both class 0 and class 1, followed by the RFC model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965bd06e",
   "metadata": {},
   "source": [
    "# Hyper Parameter tuning.\n",
    "\n",
    "Fine-tuning the Top-k models (3 < k < 5) using a GridSearchCV (that is in sklearn.model_selection ) to find the best hyperparameters and achieve the maximum performance of each of the Top-k models, then comparing them again to select the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b993eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for GBC\n",
    "gbc_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Parameter grid for LR\n",
    "lr_param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Parameter grid for RF\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV for GBC\n",
    "gbc_grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingClassifier(),\n",
    "    param_grid=gbc_param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# GridSearchCV for LR\n",
    "lr_grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=lr_param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# GridSearchCV for RF\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=rf_param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e865b01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbc_grid_search.fit(X_train_scaled, y_train)\n",
    "lr_grid_search.fit(X_train_scaled, y_train)\n",
    "rf_grid_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a3d49",
   "metadata": {},
   "source": [
    "#### Assessing the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBC - Best hyperparameters\n",
    "best_gbc_params = gbc_grid_search.best_params_\n",
    "\n",
    "# LR - Best hyperparameters\n",
    "best_lr_params = lr_grid_search.best_params_\n",
    "\n",
    "# RF - Best hyperparameters\n",
    "best_rf_params = rf_grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521155a7",
   "metadata": {},
   "source": [
    "#### Assessing the best score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBC - Best score\n",
    "best_gbc_score = gbc_grid_search.best_score_\n",
    "\n",
    "# LR - Best score\n",
    "best_lr_score = lr_grid_search.best_score_\n",
    "\n",
    "# RF - Best score\n",
    "best_rf_score = rf_grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8f284",
   "metadata": {},
   "source": [
    "Use the best hyperparameters obtained from Grid Search to train your final models and evaluate them on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03bccc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize GBC with best hyperparameters\n",
    "gbc_best = GradientBoostingClassifier(**best_gbc_params)\n",
    "gbc_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Initialize LR with best hyperparameters\n",
    "lr_best = LogisticRegression(**best_lr_params)\n",
    "lr_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Initialize RF with best hyperparameters\n",
    "rf_best = RandomForestClassifier(**best_rf_params)\n",
    "rf_best.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a file path to save all the componets in.\n",
    "if not os.path.exists(\"ml\"):\n",
    "    os.makedirs(\"ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bcc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the destination path to the \"export\" directory\n",
    "destination = os.path.join(\".\", \"ml\", \"gbc.pkl\")\n",
    "joblib.dump(gbc_best, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination2 = os.path.join(\".\", \"ml\", \"scaler.pkl\")\n",
    "joblib.dump(scaler, destination2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de42242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a0ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
